model_dim: 64
num_heads: 8
track_latent_len: 64
muon_det_latent_len: 16
muon_det_num_processors: 2
muon_det_processor_block_weight_sharing: false
encoder_num_layers: 2
decoder_num_layers: 1
widening_factor: 2
dropout_p: 0.01


module:
  _target_: deepmuonreco.nn.LatentAttentionModel

  track_dim: ${exp.track_dim}
  segment_dim: ${exp.segment_dim}
  hit_dim: ${exp.hit_dim}
  output_dim: ${exp.target_dim}

  model_dim: ${model.model_dim}
  num_heads: ${model.num_heads}
  track_latent_len: ${model.track_latent_len}
  muon_det_latent_len: ${model.muon_det_latent_len}
  muon_det_num_processors: ${model.muon_det_num_processors}
  muon_det_processor_block_weight_sharing: ${model.muon_det_processor_block_weight_sharing}
  encoder_num_layers: ${model.encoder_num_layers}
  decoder_num_layers: ${model.decoder_num_layers}
  widening_factor: ${model.widening_factor}
  dropout_p: ${model.dropout_p}


in_keys:
  - track_prep
  - [masks, track]
  - segment_prep
  - [masks, segment]
  - rechit_prep
  - [masks, rechit]

out_keys:
  - logits
